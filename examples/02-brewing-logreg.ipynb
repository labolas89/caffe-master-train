{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brewing Logistic Regression then Going Deeper\n",
    "\n",
    "While Caffe is made for deep networks it can likewise represent \"shallow\" models like logistic regression for classification. We'll do simple logistic regression on synthetic data that we'll generate and save to HDF5 to feed vectors to Caffe. Once that model is done, we'll add layers to improve accuracy. That's what Caffe is about: define a model, experiment, and then deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sklearn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-13a258632ba9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m X, y = sklearn.datasets.make_classification(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_redundant\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_informative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mn_clusters_per_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhypercube\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sklearn' is not defined"
     ]
    }
   ],
   "source": [
    "X, y = sklearn.datasets.make_classification(\n",
    "    n_samples=10000, n_features=4, n_redundant=0, n_informative=2, \n",
    "    n_clusters_per_class=2, hypercube=False, random_state=0\n",
    ")\n",
    "\n",
    "# Split into train and test\n",
    "X, Xt, y, yt = sklearn.cross_validation.train_test_split(X, y)\n",
    "\n",
    "# Visualize sample of the data\n",
    "ind = np.random.permutation(X.shape[0])[:1000]\n",
    "df = pd.DataFrame(X[ind])\n",
    "_ = pd.scatter_matrix(df, figsize=(9, 9), diagonal='kde', marker='o', s=40, alpha=.4, c=y[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthesize a dataset of 10,000 4-vectors for binary classification with 2 informative features and 2 noise features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn and evaluate scikit-learn's logistic regression with stochastic gradient descent (SGD) training. Time and check the classifier's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'sklearn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a73ed6cecd07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu\"# Train and test the scikit-learn SGD logistic regression.\\nclf = sklearn.linear_model.SGDClassifier(\\n    loss='log', n_iter=1000, penalty='l2', alpha=1e-3, class_weight='auto')\\n\\nclf.fit(X, y)\\nyt_pred = clf.predict(Xt)\\nprint('Accuracy: {:.3f}'.format(sklearn.metrics.accuracy_score(yt, yt_pred)))\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/jace/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2291\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2292\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2293\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2294\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell)\u001b[0m\n",
      "\u001b[1;32m/home/jace/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jace/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m   1035\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                 \u001b[0mtime_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m                 \u001b[0mworst_tuning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworst_tuning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jace/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'sklearn' is not defined"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Train and test the scikit-learn SGD logistic regression.\n",
    "clf = sklearn.linear_model.SGDClassifier(\n",
    "    loss='log', n_iter=1000, penalty='l2', alpha=1e-3, class_weight='auto')\n",
    "\n",
    "clf.fit(X, y)\n",
    "yt_pred = clf.predict(Xt)\n",
    "print('Accuracy: {:.3f}'.format(sklearn.metrics.accuracy_score(yt, yt_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataset to HDF5 for loading in Caffe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-eaa2cfcf6b4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Write out the data to HDF5 files in a temp directory.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# This file is assumed to be caffe_root/examples/hdf5_classification.ipynb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdirname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./examples/hdf5_classification/data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Write out the data to HDF5 files in a temp directory.\n",
    "# This file is assumed to be caffe_root/examples/hdf5_classification.ipynb\n",
    "dirname = os.path.abspath('./examples/hdf5_classification/data')\n",
    "if not os.path.exists(dirname):\n",
    "    os.makedirs(dirname)\n",
    "\n",
    "train_filename = os.path.join(dirname, 'train.h5')\n",
    "test_filename = os.path.join(dirname, 'test.h5')\n",
    "\n",
    "# HDF5DataLayer source should be a file containing a list of HDF5 filenames.\n",
    "# To show this off, we'll list the same data file twice.\n",
    "with h5py.File(train_filename, 'w') as f:\n",
    "    f['data'] = X\n",
    "    f['label'] = y.astype(np.float32)\n",
    "with open(os.path.join(dirname, 'train.txt'), 'w') as f:\n",
    "    f.write(train_filename + '\\n')\n",
    "    f.write(train_filename + '\\n')\n",
    "    \n",
    "# HDF5 is pretty efficient, but can be further compressed.\n",
    "comp_kwargs = {'compression': 'gzip', 'compression_opts': 1}\n",
    "with h5py.File(test_filename, 'w') as f:\n",
    "    f.create_dataset('data', data=Xt, **comp_kwargs)\n",
    "    f.create_dataset('label', data=yt.astype(np.float32), **comp_kwargs)\n",
    "with open(os.path.join(dirname, 'test.txt'), 'w') as f:\n",
    "    f.write(test_filename + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define logistic regression in Caffe through Python net specification. This is a quick and natural way to define nets that sidesteps manually editing the protobuf model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from caffe import layers as L\n",
    "from caffe import params as P\n",
    "\n",
    "def logreg(hdf5, batch_size):\n",
    "    # logistic regression: data, matrix multiplication, and 2-class softmax loss\n",
    "    n = caffe.NetSpec()\n",
    "    n.data, n.label = L.HDF5Data(batch_size=batch_size, source=hdf5, ntop=2)\n",
    "    n.ip1 = L.InnerProduct(n.data, num_output=2, weight_filler=dict(type='xavier'))\n",
    "    n.accuracy = L.Accuracy(n.ip1, n.label)\n",
    "    n.loss = L.SoftmaxWithLoss(n.ip1, n.label)\n",
    "    return n.to_proto()\n",
    "    \n",
    "with open('examples/hdf5_classification/logreg_auto_train.prototxt', 'w') as f:\n",
    "    f.write(str(logreg('examples/hdf5_classification/data/train.txt', 10)))\n",
    "    \n",
    "with open('examples/hdf5_classification/logreg_auto_test.prototxt', 'w') as f:\n",
    "    f.write(str(logreg('examples/hdf5_classification/data/test.txt', 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to learn and evaluate our Caffeinated logistic regression in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.782\n",
      "Accuracy: 0.782\n",
      "Accuracy: 0.782\n",
      "Accuracy: 0.782\n",
      "1 loops, best of 3: 287 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "caffe.set_mode_cpu()\n",
    "solver = caffe.get_solver('examples/hdf5_classification/solver.prototxt')\n",
    "solver.solve()\n",
    "\n",
    "accuracy = 0\n",
    "batch_size = solver.test_nets[0].blobs['data'].num\n",
    "test_iters = int(len(Xt) / batch_size)\n",
    "for i in range(test_iters):\n",
    "    solver.test_nets[0].forward()\n",
    "    accuracy += solver.test_nets[0].blobs['accuracy'].data\n",
    "accuracy /= test_iters\n",
    "\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named _caffe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5f16a783ec8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./python'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jace/temp/caffe-master-train/python/caffe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpycaffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRMSPropSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_mode_cpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_mode_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_solver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_type_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaffe_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEST\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdetector\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDetector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jace/temp/caffe-master-train/python/caffe/pycaffe.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mRMSPropSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named _caffe"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './python')\n",
    "import caffe\n",
    "\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same through the command line interface for detailed output on the model and solving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0222 13:22:25.428831 22912 caffe.cpp:177] Use CPU.\n",
      "I0222 13:22:25.429110 22912 solver.cpp:48] Initializing solver from parameters: \n",
      "train_net: \"examples/hdf5_classification/logreg_auto_train.prototxt\"\n",
      "test_net: \"examples/hdf5_classification/logreg_auto_test.prototxt\"\n",
      "test_iter: 250\n",
      "test_interval: 1000\n",
      "base_lr: 0.01\n",
      "display: 1000\n",
      "max_iter: 10000\n",
      "lr_policy: \"step\"\n",
      "gamma: 0.1\n",
      "momentum: 0.9\n",
      "weight_decay: 0.0005\n",
      "stepsize: 5000\n",
      "snapshot: 10000\n",
      "snapshot_prefix: \"examples/hdf5_classification/data/train\"\n",
      "solver_mode: CPU\n",
      "I0222 13:22:25.429234 22912 solver.cpp:81] Creating training net from train_net file: examples/hdf5_classification/logreg_auto_train.prototxt\n",
      "F0222 13:22:25.429257 22912 io.cpp:36] Check failed: fd != -1 (-1 vs. -1) File not found: examples/hdf5_classification/logreg_auto_train.prototxt\n",
      "*** Check failure stack trace: ***\n",
      "    @     0x7f5e99e8db7d  google::LogMessage::Fail()\n",
      "    @     0x7f5e99e8fc7f  google::LogMessage::SendToLog()\n",
      "    @     0x7f5e99e8d76c  google::LogMessage::Flush()\n",
      "    @     0x7f5e99e9051d  google::LogMessageFatal::~LogMessageFatal()\n",
      "    @     0x7f5e9a32bec7  caffe::ReadProtoFromTextFile()\n",
      "    @     0x7f5e9a3401bc  caffe::ReadNetParamsFromTextFileOrDie()\n",
      "    @     0x7f5e9a363167  caffe::Solver<>::InitTrainNet()\n",
      "    @     0x7f5e9a36bb94  caffe::Solver<>::Init()\n",
      "    @     0x7f5e9a36c027  caffe::Solver<>::Solver()\n",
      "    @     0x7f5e9a21cba3  caffe::Creator_SGDSolver<>()\n",
      "    @           0x40ecfe  caffe::SolverRegistry<>::CreateSolver()\n",
      "    @           0x40a935  train()\n",
      "    @           0x40736b  main\n",
      "    @     0x7f5e993cb76d  (unknown)\n",
      "    @           0x407935  (unknown)\n",
      "Aborted (core dumped)\n"
     ]
    }
   ],
   "source": [
    "!./build/tools/caffe train -solver examples/hdf5_classification/solver.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at output or the `logreg_auto_train.prototxt`, you'll see that the model is simple logistic regression.\n",
    "We can make it a little more advanced by introducing a non-linearity between weights that take the input and weights that give the output -- now we have a two-layer network.\n",
    "That network is given in `nonlinear_auto_train.prototxt`, and that's the only change made in `nonlinear_solver.prototxt` which we will now use.\n",
    "\n",
    "The final accuracy of the new network should be higher than logistic regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named _caffe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-61e93269e97d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcaffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcaffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnonlinear_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhdf5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# one small nonlinearity, one leap for model kind\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jace/temp/caffe-master-train/python/caffe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpycaffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRMSPropSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_mode_cpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_mode_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_solver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_type_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaffe_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEST\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdetector\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDetector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jace/temp/caffe-master-train/python/caffe/pycaffe.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mRMSPropSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named _caffe"
     ]
    }
   ],
   "source": [
    "from caffe import layers as L\n",
    "from caffe import params as P\n",
    "\n",
    "def nonlinear_net(hdf5, batch_size):\n",
    "    # one small nonlinearity, one leap for model kind\n",
    "    n = caffe.NetSpec()\n",
    "    n.data, n.label = L.HDF5Data(batch_size=batch_size, source=hdf5, ntop=2)\n",
    "    # define a hidden layer of dimension 40\n",
    "    n.ip1 = L.InnerProduct(n.data, num_output=40, weight_filler=dict(type='xavier'))\n",
    "    # transform the output through the ReLU (rectified linear) non-linearity\n",
    "    n.relu1 = L.ReLU(n.ip1, in_place=True)\n",
    "    # score the (now non-linear) features\n",
    "    n.ip2 = L.InnerProduct(n.ip1, num_output=2, weight_filler=dict(type='xavier'))\n",
    "    # same accuracy and loss as before\n",
    "    n.accuracy = L.Accuracy(n.ip2, n.label)\n",
    "    n.loss = L.SoftmaxWithLoss(n.ip2, n.label)\n",
    "    return n.to_proto()\n",
    "    \n",
    "with open('examples/hdf5_classification/nonlinear_auto_train.prototxt', 'w') as f:\n",
    "    f.write(str(nonlinear_net('examples/hdf5_classification/data/train.txt', 10)))\n",
    "    \n",
    "with open('examples/hdf5_classification/nonlinear_auto_test.prototxt', 'w') as f:\n",
    "    f.write(str(nonlinear_net('examples/hdf5_classification/data/test.txt', 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'caffe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5d57be6955d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'caffe.set_mode_cpu()\\nsolver = caffe.get_solver(\\'examples/hdf5_classification/nonlinear_solver.prototxt\\')\\nsolver.solve()\\n\\naccuracy = 0\\nbatch_size = solver.test_nets[0].blobs[\\'data\\'].num\\ntest_iters = int(len(Xt) / batch_size)\\nfor i in range(test_iters):\\n    solver.test_nets[0].forward()\\n    accuracy += solver.test_nets[0].blobs[\\'accuracy\\'].data\\naccuracy /= test_iters\\n\\nprint(\"Accuracy: {:.3f}\".format(accuracy))'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/jace/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2291\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2292\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2293\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2294\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell)\u001b[0m\n",
      "\u001b[1;32m/home/jace/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jace/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m   1035\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                 \u001b[0mtime_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m                 \u001b[0mworst_tuning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworst_tuning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jace/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'caffe' is not defined"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "caffe.set_mode_cpu()\n",
    "solver = caffe.get_solver('examples/hdf5_classification/nonlinear_solver.prototxt')\n",
    "solver.solve()\n",
    "\n",
    "accuracy = 0\n",
    "batch_size = solver.test_nets[0].blobs['data'].num\n",
    "test_iters = int(len(Xt) / batch_size)\n",
    "for i in range(test_iters):\n",
    "    solver.test_nets[0].forward()\n",
    "    accuracy += solver.test_nets[0].blobs['accuracy'].data\n",
    "accuracy /= test_iters\n",
    "\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same through the command line interface for detailed output on the model and solving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0222 13:22:28.714685 22927 caffe.cpp:177] Use CPU.\n",
      "I0222 13:22:28.714980 22927 solver.cpp:48] Initializing solver from parameters: \n",
      "train_net: \"examples/hdf5_classification/nonlinear_auto_train.prototxt\"\n",
      "test_net: \"examples/hdf5_classification/nonlinear_auto_test.prototxt\"\n",
      "test_iter: 250\n",
      "test_interval: 1000\n",
      "base_lr: 0.01\n",
      "display: 1000\n",
      "max_iter: 40000\n",
      "lr_policy: \"step\"\n",
      "gamma: 0.1\n",
      "momentum: 0.9\n",
      "weight_decay: 0.0005\n",
      "stepsize: 10000\n",
      "snapshot: 40000\n",
      "snapshot_prefix: \"examples/hdf5_classification/data/train\"\n",
      "solver_mode: CPU\n",
      "I0222 13:22:28.715111 22927 solver.cpp:81] Creating training net from train_net file: examples/hdf5_classification/nonlinear_auto_train.prototxt\n",
      "I0222 13:22:28.715320 22927 net.cpp:49] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TRAIN\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"HDF5Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  hdf5_data_param {\n",
      "    source: \"git/data/train_datalist_new2d.txt\"\n",
      "    batch_size: 900\n",
      "    shuffle: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ip1\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"data\"\n",
      "  top: \"ip1\"\n",
      "  inner_product_param {\n",
      "    num_output: 40\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip2\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip2\"\n",
      "  inner_product_param {\n",
      "    num_output: 3\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"ip2\"\n",
      "  bottom: \"label\"\n",
      "  top: \"accuracy\"\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"ip2\"\n",
      "  bottom: \"label\"\n",
      "  top: \"loss\"\n",
      "}\n",
      "I0222 13:22:28.715608 22927 layer_factory.hpp:77] Creating layer data\n",
      "I0222 13:22:28.715633 22927 net.cpp:106] Creating Layer data\n",
      "I0222 13:22:28.715643 22927 net.cpp:411] data -> data\n",
      "I0222 13:22:28.715670 22927 net.cpp:411] data -> label\n",
      "I0222 13:22:28.715685 22927 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: git/data/train_datalist_new2d.txt\n",
      "I0222 13:22:28.715728 22927 hdf5_data_layer.cpp:93] Number of HDF5 files: 9\n",
      "I0222 13:22:28.717108 22927 hdf5.cpp:35] Datatype class: H5T_INTEGER\n",
      "I0222 13:22:28.762815 22927 net.cpp:150] Setting up data\n",
      "I0222 13:22:28.762866 22927 net.cpp:157] Top shape: 900 4 (3600)\n",
      "I0222 13:22:28.762878 22927 net.cpp:157] Top shape: 900 1 (900)\n",
      "I0222 13:22:28.762884 22927 net.cpp:165] Memory required for data: 18000\n",
      "I0222 13:22:28.762897 22927 layer_factory.hpp:77] Creating layer label_data_1_split\n",
      "I0222 13:22:28.762913 22927 net.cpp:106] Creating Layer label_data_1_split\n",
      "I0222 13:22:28.762922 22927 net.cpp:454] label_data_1_split <- label\n",
      "I0222 13:22:28.762935 22927 net.cpp:411] label_data_1_split -> label_data_1_split_0\n",
      "I0222 13:22:28.762950 22927 net.cpp:411] label_data_1_split -> label_data_1_split_1\n",
      "I0222 13:22:28.762965 22927 net.cpp:150] Setting up label_data_1_split\n",
      "I0222 13:22:28.762974 22927 net.cpp:157] Top shape: 900 1 (900)\n",
      "I0222 13:22:28.762980 22927 net.cpp:157] Top shape: 900 1 (900)\n",
      "I0222 13:22:28.762986 22927 net.cpp:165] Memory required for data: 25200\n",
      "I0222 13:22:28.762991 22927 layer_factory.hpp:77] Creating layer ip1\n",
      "I0222 13:22:28.763005 22927 net.cpp:106] Creating Layer ip1\n",
      "I0222 13:22:28.763011 22927 net.cpp:454] ip1 <- data\n",
      "I0222 13:22:28.763020 22927 net.cpp:411] ip1 -> ip1\n",
      "I0222 13:22:28.763471 22927 net.cpp:150] Setting up ip1\n",
      "I0222 13:22:28.763494 22927 net.cpp:157] Top shape: 900 40 (36000)\n",
      "I0222 13:22:28.763500 22927 net.cpp:165] Memory required for data: 169200\n",
      "I0222 13:22:28.763519 22927 layer_factory.hpp:77] Creating layer relu1\n",
      "I0222 13:22:28.763530 22927 net.cpp:106] Creating Layer relu1\n",
      "I0222 13:22:28.763537 22927 net.cpp:454] relu1 <- ip1\n",
      "I0222 13:22:28.763545 22927 net.cpp:397] relu1 -> ip1 (in-place)\n",
      "I0222 13:22:28.763556 22927 net.cpp:150] Setting up relu1\n",
      "I0222 13:22:28.763562 22927 net.cpp:157] Top shape: 900 40 (36000)\n",
      "I0222 13:22:28.763568 22927 net.cpp:165] Memory required for data: 313200\n",
      "I0222 13:22:28.763574 22927 layer_factory.hpp:77] Creating layer ip2\n",
      "I0222 13:22:28.763584 22927 net.cpp:106] Creating Layer ip2\n",
      "I0222 13:22:28.763591 22927 net.cpp:454] ip2 <- ip1\n",
      "I0222 13:22:28.763597 22927 net.cpp:411] ip2 -> ip2\n",
      "I0222 13:22:28.763615 22927 net.cpp:150] Setting up ip2\n",
      "I0222 13:22:28.763648 22927 net.cpp:157] Top shape: 900 3 (2700)\n",
      "I0222 13:22:28.763654 22927 net.cpp:165] Memory required for data: 324000\n",
      "I0222 13:22:28.763664 22927 layer_factory.hpp:77] Creating layer ip2_ip2_0_split\n",
      "I0222 13:22:28.763672 22927 net.cpp:106] Creating Layer ip2_ip2_0_split\n",
      "I0222 13:22:28.763679 22927 net.cpp:454] ip2_ip2_0_split <- ip2\n",
      "I0222 13:22:28.763685 22927 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_0\n",
      "I0222 13:22:28.763694 22927 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_1\n",
      "I0222 13:22:28.763702 22927 net.cpp:150] Setting up ip2_ip2_0_split\n",
      "I0222 13:22:28.763710 22927 net.cpp:157] Top shape: 900 3 (2700)\n",
      "I0222 13:22:28.763716 22927 net.cpp:157] Top shape: 900 3 (2700)\n",
      "I0222 13:22:28.763721 22927 net.cpp:165] Memory required for data: 345600\n",
      "I0222 13:22:28.763727 22927 layer_factory.hpp:77] Creating layer accuracy\n",
      "I0222 13:22:28.763736 22927 net.cpp:106] Creating Layer accuracy\n",
      "I0222 13:22:28.763742 22927 net.cpp:454] accuracy <- ip2_ip2_0_split_0\n",
      "I0222 13:22:28.763749 22927 net.cpp:454] accuracy <- label_data_1_split_0\n",
      "I0222 13:22:28.763758 22927 net.cpp:411] accuracy -> accuracy\n",
      "I0222 13:22:28.763769 22927 net.cpp:150] Setting up accuracy\n",
      "I0222 13:22:28.763777 22927 net.cpp:157] Top shape: (1)\n",
      "I0222 13:22:28.763782 22927 net.cpp:165] Memory required for data: 345604\n",
      "I0222 13:22:28.763788 22927 layer_factory.hpp:77] Creating layer loss\n",
      "I0222 13:22:28.763797 22927 net.cpp:106] Creating Layer loss\n",
      "I0222 13:22:28.763803 22927 net.cpp:454] loss <- ip2_ip2_0_split_1\n",
      "I0222 13:22:28.763810 22927 net.cpp:454] loss <- label_data_1_split_1\n",
      "I0222 13:22:28.763818 22927 net.cpp:411] loss -> loss\n",
      "I0222 13:22:28.763852 22927 layer_factory.hpp:77] Creating layer loss\n",
      "I0222 13:22:28.763877 22927 net.cpp:150] Setting up loss\n",
      "I0222 13:22:28.763886 22927 net.cpp:157] Top shape: (1)\n",
      "I0222 13:22:28.763892 22927 net.cpp:160]     with loss weight 1\n",
      "I0222 13:22:28.763913 22927 net.cpp:165] Memory required for data: 345608\n",
      "I0222 13:22:28.763919 22927 net.cpp:226] loss needs backward computation.\n",
      "I0222 13:22:28.763926 22927 net.cpp:228] accuracy does not need backward computation.\n",
      "I0222 13:22:28.763932 22927 net.cpp:226] ip2_ip2_0_split needs backward computation.\n",
      "I0222 13:22:28.763938 22927 net.cpp:226] ip2 needs backward computation.\n",
      "I0222 13:22:28.763944 22927 net.cpp:226] relu1 needs backward computation.\n",
      "I0222 13:22:28.763949 22927 net.cpp:226] ip1 needs backward computation.\n",
      "I0222 13:22:28.763957 22927 net.cpp:228] label_data_1_split does not need backward computation.\n",
      "I0222 13:22:28.763962 22927 net.cpp:228] data does not need backward computation.\n",
      "I0222 13:22:28.763967 22927 net.cpp:270] This network produces output accuracy\n",
      "I0222 13:22:28.763974 22927 net.cpp:270] This network produces output loss\n",
      "I0222 13:22:28.763986 22927 net.cpp:283] Network initialization done.\n",
      "I0222 13:22:28.764124 22927 solver.cpp:181] Creating test net (#0) specified by test_net file: examples/hdf5_classification/nonlinear_auto_test.prototxt\n",
      "I0222 13:22:28.764178 22927 net.cpp:49] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"HDF5Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  hdf5_data_param {\n",
      "    source: \"git/data/test_datalist_new2d.txt\"\n",
      "    batch_size: 900\n",
      "    shuffle: true\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ip1\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"data\"\n",
      "  top: \"ip1\"\n",
      "  inner_product_param {\n",
      "    num_output: 40\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip2\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip2\"\n",
      "  inner_product_param {\n",
      "    num_output: 3\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"ip2\"\n",
      "  bottom: \"label\"\n",
      "  top: \"accuracy\"\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"ip2\"\n",
      "  bottom: \"label\"\n",
      "  top: \"loss\"\n",
      "}\n",
      "I0222 13:22:28.764353 22927 layer_factory.hpp:77] Creating layer data\n",
      "I0222 13:22:28.764364 22927 net.cpp:106] Creating Layer data\n",
      "I0222 13:22:28.764370 22927 net.cpp:411] data -> data\n",
      "I0222 13:22:28.764380 22927 net.cpp:411] data -> label\n",
      "I0222 13:22:28.764401 22927 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: git/data/test_datalist_new2d.txt\n",
      "I0222 13:22:28.764421 22927 hdf5_data_layer.cpp:93] Number of HDF5 files: 1\n",
      "I0222 13:22:28.819484 22927 net.cpp:150] Setting up data\n",
      "I0222 13:22:28.819573 22927 net.cpp:157] Top shape: 900 4 (3600)\n",
      "I0222 13:22:28.819586 22927 net.cpp:157] Top shape: 900 1 (900)\n",
      "I0222 13:22:28.819592 22927 net.cpp:165] Memory required for data: 18000\n",
      "I0222 13:22:28.819602 22927 layer_factory.hpp:77] Creating layer label_data_1_split\n",
      "I0222 13:22:28.819617 22927 net.cpp:106] Creating Layer label_data_1_split\n",
      "I0222 13:22:28.819623 22927 net.cpp:454] label_data_1_split <- label\n",
      "I0222 13:22:28.819633 22927 net.cpp:411] label_data_1_split -> label_data_1_split_0\n",
      "I0222 13:22:28.819646 22927 net.cpp:411] label_data_1_split -> label_data_1_split_1\n",
      "I0222 13:22:28.819656 22927 net.cpp:150] Setting up label_data_1_split\n",
      "I0222 13:22:28.819664 22927 net.cpp:157] Top shape: 900 1 (900)\n",
      "I0222 13:22:28.819671 22927 net.cpp:157] Top shape: 900 1 (900)\n",
      "I0222 13:22:28.819677 22927 net.cpp:165] Memory required for data: 25200\n",
      "I0222 13:22:28.819684 22927 layer_factory.hpp:77] Creating layer ip1\n",
      "I0222 13:22:28.819694 22927 net.cpp:106] Creating Layer ip1\n",
      "I0222 13:22:28.819746 22927 net.cpp:454] ip1 <- data\n",
      "I0222 13:22:28.819757 22927 net.cpp:411] ip1 -> ip1\n",
      "I0222 13:22:28.819782 22927 net.cpp:150] Setting up ip1\n",
      "I0222 13:22:28.819792 22927 net.cpp:157] Top shape: 900 40 (36000)\n",
      "I0222 13:22:28.819797 22927 net.cpp:165] Memory required for data: 169200\n",
      "I0222 13:22:28.819810 22927 layer_factory.hpp:77] Creating layer relu1\n",
      "I0222 13:22:28.819819 22927 net.cpp:106] Creating Layer relu1\n",
      "I0222 13:22:28.819826 22927 net.cpp:454] relu1 <- ip1\n",
      "I0222 13:22:28.819833 22927 net.cpp:397] relu1 -> ip1 (in-place)\n",
      "I0222 13:22:28.819841 22927 net.cpp:150] Setting up relu1\n",
      "I0222 13:22:28.819881 22927 net.cpp:157] Top shape: 900 40 (36000)\n",
      "I0222 13:22:28.819891 22927 net.cpp:165] Memory required for data: 313200\n",
      "I0222 13:22:28.819897 22927 layer_factory.hpp:77] Creating layer ip2\n",
      "I0222 13:22:28.819906 22927 net.cpp:106] Creating Layer ip2\n",
      "I0222 13:22:28.819913 22927 net.cpp:454] ip2 <- ip1\n",
      "I0222 13:22:28.819921 22927 net.cpp:411] ip2 -> ip2\n",
      "I0222 13:22:28.819936 22927 net.cpp:150] Setting up ip2\n",
      "I0222 13:22:28.819944 22927 net.cpp:157] Top shape: 900 3 (2700)\n",
      "I0222 13:22:28.819950 22927 net.cpp:165] Memory required for data: 324000\n",
      "I0222 13:22:28.819960 22927 layer_factory.hpp:77] Creating layer ip2_ip2_0_split\n",
      "I0222 13:22:28.819968 22927 net.cpp:106] Creating Layer ip2_ip2_0_split\n",
      "I0222 13:22:28.819973 22927 net.cpp:454] ip2_ip2_0_split <- ip2\n",
      "I0222 13:22:28.819982 22927 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_0\n",
      "I0222 13:22:28.819989 22927 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_1\n",
      "I0222 13:22:28.820029 22927 net.cpp:150] Setting up ip2_ip2_0_split\n",
      "I0222 13:22:28.820040 22927 net.cpp:157] Top shape: 900 3 (2700)\n",
      "I0222 13:22:28.820046 22927 net.cpp:157] Top shape: 900 3 (2700)\n",
      "I0222 13:22:28.820052 22927 net.cpp:165] Memory required for data: 345600\n",
      "I0222 13:22:28.820058 22927 layer_factory.hpp:77] Creating layer accuracy\n",
      "I0222 13:22:28.820067 22927 net.cpp:106] Creating Layer accuracy\n",
      "I0222 13:22:28.820073 22927 net.cpp:454] accuracy <- ip2_ip2_0_split_0\n",
      "I0222 13:22:28.820080 22927 net.cpp:454] accuracy <- label_data_1_split_0\n",
      "I0222 13:22:28.820088 22927 net.cpp:411] accuracy -> accuracy\n",
      "I0222 13:22:28.820098 22927 net.cpp:150] Setting up accuracy\n",
      "I0222 13:22:28.820106 22927 net.cpp:157] Top shape: (1)\n",
      "I0222 13:22:28.820111 22927 net.cpp:165] Memory required for data: 345604\n",
      "I0222 13:22:28.820117 22927 layer_factory.hpp:77] Creating layer loss\n",
      "I0222 13:22:28.820124 22927 net.cpp:106] Creating Layer loss\n",
      "I0222 13:22:28.820130 22927 net.cpp:454] loss <- ip2_ip2_0_split_1\n",
      "I0222 13:22:28.820137 22927 net.cpp:454] loss <- label_data_1_split_1\n",
      "I0222 13:22:28.820144 22927 net.cpp:411] loss -> loss\n",
      "I0222 13:22:28.820204 22927 layer_factory.hpp:77] Creating layer loss\n",
      "I0222 13:22:28.820225 22927 net.cpp:150] Setting up loss\n",
      "I0222 13:22:28.820256 22927 net.cpp:157] Top shape: (1)\n",
      "I0222 13:22:28.820262 22927 net.cpp:160]     with loss weight 1\n",
      "I0222 13:22:28.820274 22927 net.cpp:165] Memory required for data: 345608\n",
      "I0222 13:22:28.820281 22927 net.cpp:226] loss needs backward computation.\n",
      "I0222 13:22:28.820287 22927 net.cpp:228] accuracy does not need backward computation.\n",
      "I0222 13:22:28.820294 22927 net.cpp:226] ip2_ip2_0_split needs backward computation.\n",
      "I0222 13:22:28.820332 22927 net.cpp:226] ip2 needs backward computation.\n",
      "I0222 13:22:28.820341 22927 net.cpp:226] relu1 needs backward computation.\n",
      "I0222 13:22:28.820348 22927 net.cpp:226] ip1 needs backward computation.\n",
      "I0222 13:22:28.820353 22927 net.cpp:228] label_data_1_split does not need backward computation.\n",
      "I0222 13:22:28.820360 22927 net.cpp:228] data does not need backward computation.\n",
      "I0222 13:22:28.820366 22927 net.cpp:270] This network produces output accuracy\n",
      "I0222 13:22:28.820374 22927 net.cpp:270] This network produces output loss\n",
      "I0222 13:22:28.820384 22927 net.cpp:283] Network initialization done.\n",
      "I0222 13:22:28.820417 22927 solver.cpp:60] Solver scaffolding done.\n",
      "I0222 13:22:28.820441 22927 caffe.cpp:212] Starting Optimization\n",
      "I0222 13:22:28.820485 22927 solver.cpp:295] Solving \n",
      "I0222 13:22:28.820497 22927 solver.cpp:296] Learning Rate Policy: step\n",
      "I0222 13:22:28.820510 22927 solver.cpp:348] Iteration 0, Testing net (#0)\n",
      "I0222 13:22:29.036268 22927 solver.cpp:432]     Test net output #0: accuracy = 0.215756 [ 0 : 0% ] [ 1 : 0% ] [ 2 : 100% ] \n",
      "I0222 13:22:29.036337 22927 solver.cpp:438]     Test net output #1: loss = 68.4929 (* 1 = 68.4929 loss)\n",
      "I0222 13:22:29.037724 22927 solver.cpp:237] Iteration 0, loss = 58.8064\n",
      "I0222 13:22:29.037746 22927 solver.cpp:253]     Train net output #0: accuracy = 0.326667 [ 0 : 0% ] [ 1 : 0% ] [ 2 : 100% ] \n",
      "I0222 13:22:29.037762 22927 solver.cpp:259]     Train net output #1: loss = 58.8064 (* 1 = 58.8064 loss)\n",
      "I0222 13:22:29.037778 22927 sgd_solver.cpp:106] Iteration 0, lr = 0.01\n",
      "I0222 13:22:31.835883 22927 solver.cpp:348] Iteration 1000, Testing net (#0)\n",
      "I0222 13:22:32.073947 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716498 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:32.074015 22927 solver.cpp:438]     Test net output #1: loss = 0.763107 (* 1 = 0.763107 loss)\n",
      "I0222 13:22:32.085304 22927 solver.cpp:237] Iteration 1000, loss = 0.785388\n",
      "I0222 13:22:32.085358 22927 solver.cpp:253]     Train net output #0: accuracy = 0.692222 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:32.085376 22927 solver.cpp:259]     Train net output #1: loss = 0.785388 (* 1 = 0.785388 loss)\n",
      "I0222 13:22:32.085387 22927 sgd_solver.cpp:106] Iteration 1000, lr = 0.01\n",
      "I0222 13:22:34.936697 22927 solver.cpp:348] Iteration 2000, Testing net (#0)\n",
      "I0222 13:22:35.191992 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716049 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:35.192059 22927 solver.cpp:438]     Test net output #1: loss = 0.763969 (* 1 = 0.763969 loss)\n",
      "I0222 13:22:35.193320 22927 solver.cpp:237] Iteration 2000, loss = 0.82699\n",
      "I0222 13:22:35.193342 22927 solver.cpp:253]     Train net output #0: accuracy = 0.674444 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:35.193356 22927 solver.cpp:259]     Train net output #1: loss = 0.82699 (* 1 = 0.82699 loss)\n",
      "I0222 13:22:35.193367 22927 sgd_solver.cpp:106] Iteration 2000, lr = 0.01\n",
      "I0222 13:22:37.974287 22927 solver.cpp:348] Iteration 3000, Testing net (#0)\n",
      "I0222 13:22:38.205139 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716306 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:38.205214 22927 solver.cpp:438]     Test net output #1: loss = 0.763824 (* 1 = 0.763824 loss)\n",
      "I0222 13:22:38.206675 22927 solver.cpp:237] Iteration 3000, loss = 0.874291\n",
      "I0222 13:22:38.206698 22927 solver.cpp:253]     Train net output #0: accuracy = 0.61 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:38.206717 22927 solver.cpp:259]     Train net output #1: loss = 0.874291 (* 1 = 0.874291 loss)\n",
      "I0222 13:22:38.206727 22927 sgd_solver.cpp:106] Iteration 3000, lr = 0.01\n",
      "I0222 13:22:40.883994 22927 solver.cpp:348] Iteration 4000, Testing net (#0)\n",
      "I0222 13:22:41.114833 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716373 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:41.114900 22927 solver.cpp:438]     Test net output #1: loss = 0.812303 (* 1 = 0.812303 loss)\n",
      "I0222 13:22:41.116236 22927 solver.cpp:237] Iteration 4000, loss = 0.949268\n",
      "I0222 13:22:41.116256 22927 solver.cpp:253]     Train net output #0: accuracy = 0.52 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:41.116271 22927 solver.cpp:259]     Train net output #1: loss = 0.949268 (* 1 = 0.949268 loss)\n",
      "I0222 13:22:41.116281 22927 sgd_solver.cpp:106] Iteration 4000, lr = 0.01\n",
      "I0222 13:22:43.903055 22927 solver.cpp:348] Iteration 5000, Testing net (#0)\n",
      "I0222 13:22:44.124795 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716453 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:44.124876 22927 solver.cpp:438]     Test net output #1: loss = 0.799257 (* 1 = 0.799257 loss)\n",
      "I0222 13:22:44.126346 22927 solver.cpp:237] Iteration 5000, loss = 0.864571\n",
      "I0222 13:22:44.126370 22927 solver.cpp:253]     Train net output #0: accuracy = 0.653333 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:44.126387 22927 solver.cpp:259]     Train net output #1: loss = 0.864571 (* 1 = 0.864571 loss)\n",
      "I0222 13:22:44.126399 22927 sgd_solver.cpp:106] Iteration 5000, lr = 0.01\n",
      "I0222 13:22:47.252449 22927 solver.cpp:348] Iteration 6000, Testing net (#0)\n",
      "I0222 13:22:47.496971 22927 solver.cpp:432]     Test net output #0: accuracy = 0.715889 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:47.497040 22927 solver.cpp:438]     Test net output #1: loss = 0.777434 (* 1 = 0.777434 loss)\n",
      "I0222 13:22:47.498569 22927 solver.cpp:237] Iteration 6000, loss = 0.842195\n",
      "I0222 13:22:47.498615 22927 solver.cpp:253]     Train net output #0: accuracy = 0.67 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:47.498657 22927 solver.cpp:259]     Train net output #1: loss = 0.842195 (* 1 = 0.842195 loss)\n",
      "I0222 13:22:47.498687 22927 sgd_solver.cpp:106] Iteration 6000, lr = 0.01\n",
      "I0222 13:22:50.651077 22927 solver.cpp:348] Iteration 7000, Testing net (#0)\n",
      "I0222 13:22:50.878341 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716346 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:50.878408 22927 solver.cpp:438]     Test net output #1: loss = 0.796256 (* 1 = 0.796256 loss)\n",
      "I0222 13:22:50.880362 22927 solver.cpp:237] Iteration 7000, loss = 0.881142\n",
      "I0222 13:22:50.880389 22927 solver.cpp:253]     Train net output #0: accuracy = 0.624444 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:50.880404 22927 solver.cpp:259]     Train net output #1: loss = 0.881142 (* 1 = 0.881142 loss)\n",
      "I0222 13:22:50.880414 22927 sgd_solver.cpp:106] Iteration 7000, lr = 0.01\n",
      "I0222 13:22:53.925469 22927 solver.cpp:348] Iteration 8000, Testing net (#0)\n",
      "I0222 13:22:54.163568 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716075 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:54.163631 22927 solver.cpp:438]     Test net output #1: loss = 0.780373 (* 1 = 0.780373 loss)\n",
      "I0222 13:22:54.164891 22927 solver.cpp:237] Iteration 8000, loss = 0.851314\n",
      "I0222 13:22:54.164911 22927 solver.cpp:253]     Train net output #0: accuracy = 0.628889 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:54.164926 22927 solver.cpp:259]     Train net output #1: loss = 0.851314 (* 1 = 0.851314 loss)\n",
      "I0222 13:22:54.164935 22927 sgd_solver.cpp:106] Iteration 8000, lr = 0.01\n",
      "I0222 13:22:56.918902 22927 solver.cpp:348] Iteration 9000, Testing net (#0)\n",
      "I0222 13:22:57.152420 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716454 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:57.152482 22927 solver.cpp:438]     Test net output #1: loss = 0.771769 (* 1 = 0.771769 loss)\n",
      "I0222 13:22:57.153790 22927 solver.cpp:237] Iteration 9000, loss = 0.858474\n",
      "I0222 13:22:57.153812 22927 solver.cpp:253]     Train net output #0: accuracy = 0.631111 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:22:57.153826 22927 solver.cpp:259]     Train net output #1: loss = 0.858474 (* 1 = 0.858474 loss)\n",
      "I0222 13:22:57.153836 22927 sgd_solver.cpp:106] Iteration 9000, lr = 0.01\n",
      "I0222 13:23:00.067164 22927 solver.cpp:348] Iteration 10000, Testing net (#0)\n",
      "I0222 13:23:00.304774 22927 solver.cpp:432]     Test net output #0: accuracy = 0.71624 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:00.304842 22927 solver.cpp:438]     Test net output #1: loss = 0.766699 (* 1 = 0.766699 loss)\n",
      "I0222 13:23:00.306108 22927 solver.cpp:237] Iteration 10000, loss = 0.873866\n",
      "I0222 13:23:00.306128 22927 solver.cpp:253]     Train net output #0: accuracy = 0.615556 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:00.306143 22927 solver.cpp:259]     Train net output #1: loss = 0.873866 (* 1 = 0.873866 loss)\n",
      "I0222 13:23:00.306152 22927 sgd_solver.cpp:106] Iteration 10000, lr = 0.001\n",
      "I0222 13:23:03.578356 22927 solver.cpp:348] Iteration 11000, Testing net (#0)\n",
      "I0222 13:23:03.809886 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716182 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:03.809954 22927 solver.cpp:438]     Test net output #1: loss = 0.777166 (* 1 = 0.777166 loss)\n",
      "I0222 13:23:03.811208 22927 solver.cpp:237] Iteration 11000, loss = 0.899372\n",
      "I0222 13:23:03.811226 22927 solver.cpp:253]     Train net output #0: accuracy = 0.575556 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:03.811239 22927 solver.cpp:259]     Train net output #1: loss = 0.899372 (* 1 = 0.899372 loss)\n",
      "I0222 13:23:03.811249 22927 sgd_solver.cpp:106] Iteration 11000, lr = 0.001\n",
      "I0222 13:23:07.190482 22927 solver.cpp:348] Iteration 12000, Testing net (#0)\n",
      "I0222 13:23:07.429849 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716293 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:07.429913 22927 solver.cpp:438]     Test net output #1: loss = 0.782846 (* 1 = 0.782846 loss)\n",
      "I0222 13:23:07.431186 22927 solver.cpp:237] Iteration 12000, loss = 0.872453\n",
      "I0222 13:23:07.431205 22927 solver.cpp:253]     Train net output #0: accuracy = 0.594444 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:07.431218 22927 solver.cpp:259]     Train net output #1: loss = 0.872453 (* 1 = 0.872453 loss)\n",
      "I0222 13:23:07.431228 22927 sgd_solver.cpp:106] Iteration 12000, lr = 0.001\n",
      "I0222 13:23:10.240227 22927 solver.cpp:348] Iteration 13000, Testing net (#0)\n",
      "I0222 13:23:10.456748 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716147 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:10.456823 22927 solver.cpp:438]     Test net output #1: loss = 0.779265 (* 1 = 0.779265 loss)\n",
      "I0222 13:23:10.458071 22927 solver.cpp:237] Iteration 13000, loss = 0.860768\n",
      "I0222 13:23:10.458091 22927 solver.cpp:253]     Train net output #0: accuracy = 0.616667 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:10.458106 22927 solver.cpp:259]     Train net output #1: loss = 0.860768 (* 1 = 0.860768 loss)\n",
      "I0222 13:23:10.458115 22927 sgd_solver.cpp:106] Iteration 13000, lr = 0.001\n",
      "I0222 13:23:13.353023 22927 solver.cpp:348] Iteration 14000, Testing net (#0)\n",
      "I0222 13:23:13.581019 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716396 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:13.581084 22927 solver.cpp:438]     Test net output #1: loss = 0.780895 (* 1 = 0.780895 loss)\n",
      "I0222 13:23:13.582357 22927 solver.cpp:237] Iteration 14000, loss = 0.855053\n",
      "I0222 13:23:13.582383 22927 solver.cpp:253]     Train net output #0: accuracy = 0.63 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:13.582398 22927 solver.cpp:259]     Train net output #1: loss = 0.855053 (* 1 = 0.855053 loss)\n",
      "I0222 13:23:13.582409 22927 sgd_solver.cpp:106] Iteration 14000, lr = 0.001\n",
      "I0222 13:23:16.594589 22927 solver.cpp:348] Iteration 15000, Testing net (#0)\n",
      "I0222 13:23:16.813997 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716218 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:16.814062 22927 solver.cpp:438]     Test net output #1: loss = 0.78408 (* 1 = 0.78408 loss)\n",
      "I0222 13:23:16.815306 22927 solver.cpp:237] Iteration 15000, loss = 0.815137\n",
      "I0222 13:23:16.815328 22927 solver.cpp:253]     Train net output #0: accuracy = 0.671111 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:16.815343 22927 solver.cpp:259]     Train net output #1: loss = 0.815137 (* 1 = 0.815137 loss)\n",
      "I0222 13:23:16.815353 22927 sgd_solver.cpp:106] Iteration 15000, lr = 0.001\n",
      "I0222 13:23:19.942972 22927 solver.cpp:348] Iteration 16000, Testing net (#0)\n",
      "I0222 13:23:20.174406 22927 solver.cpp:432]     Test net output #0: accuracy = 0.71596 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:20.174541 22927 solver.cpp:438]     Test net output #1: loss = 0.78091 (* 1 = 0.78091 loss)\n",
      "I0222 13:23:20.176205 22927 solver.cpp:237] Iteration 16000, loss = 0.873393\n",
      "I0222 13:23:20.176236 22927 solver.cpp:253]     Train net output #0: accuracy = 0.6 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:20.176252 22927 solver.cpp:259]     Train net output #1: loss = 0.873393 (* 1 = 0.873393 loss)\n",
      "I0222 13:23:20.176261 22927 sgd_solver.cpp:106] Iteration 16000, lr = 0.001\n",
      "I0222 13:23:22.890467 22927 solver.cpp:348] Iteration 17000, Testing net (#0)\n",
      "I0222 13:23:23.122577 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716351 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:23.122638 22927 solver.cpp:438]     Test net output #1: loss = 0.777802 (* 1 = 0.777802 loss)\n",
      "I0222 13:23:23.123883 22927 solver.cpp:237] Iteration 17000, loss = 0.798253\n",
      "I0222 13:23:23.123903 22927 solver.cpp:253]     Train net output #0: accuracy = 0.677778 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:23.123916 22927 solver.cpp:259]     Train net output #1: loss = 0.798253 (* 1 = 0.798253 loss)\n",
      "I0222 13:23:23.123926 22927 sgd_solver.cpp:106] Iteration 17000, lr = 0.001\n",
      "I0222 13:23:26.297901 22927 solver.cpp:348] Iteration 18000, Testing net (#0)\n",
      "I0222 13:23:26.560997 22927 solver.cpp:432]     Test net output #0: accuracy = 0.716364 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:26.561067 22927 solver.cpp:438]     Test net output #1: loss = 0.778668 (* 1 = 0.778668 loss)\n",
      "I0222 13:23:26.562507 22927 solver.cpp:237] Iteration 18000, loss = 0.882458\n",
      "I0222 13:23:26.562559 22927 solver.cpp:253]     Train net output #0: accuracy = 0.591111 [ 0 : 100% ] [ 1 : 0% ] [ 2 : 0% ] \n",
      "I0222 13:23:26.562590 22927 solver.cpp:259]     Train net output #1: loss = 0.882458 (* 1 = 0.882458 loss)\n",
      "I0222 13:23:26.562611 22927 sgd_solver.cpp:106] Iteration 18000, lr = 0.001\n"
     ]
    }
   ],
   "source": [
    "!./build/tools/caffe train -solver examples/hdf5_classification/nonlinear_solver.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean up (comment this out if you want to examine the hdf5_classification/data directory).\n",
    "shutil.rmtree(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "description": "Use Caffe as a generic SGD optimizer to train logistic regression on non-image HDF5 data.",
  "example_name": "Off-the-shelf SGD for classification",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "priority": 3
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
